{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6f89972",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irohc\\anaconda3\\envs\\drl_proj\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\irohc\\anaconda3\\envs\\drl_proj\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\irohc\\anaconda3\\envs\\drl_proj\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\irohc\\anaconda3\\envs\\drl_proj\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\irohc\\anaconda3\\envs\\drl_proj\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\irohc\\anaconda3\\envs\\drl_proj\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from imutils import paths\n",
    "\n",
    "import gzip\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from rl_with_videos.preprocessors.convnet import convnet_preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5434e1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_PATH = \"C:/nyu/DRL/final_project/dataset/acrobot-975-1000.pkl\"\n",
    "NEGATIVE_PATH = \"C:/nyu/DRL/final_project/dataset/acrobot-25-50.pkl\"\n",
    "\n",
    "MAX_SEQ_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d522dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sequence(VIDEO_PATH):\n",
    "    with gzip.open(VIDEO_PATH, 'rb') as f:\n",
    "        latest_samples = pickle.load(f)\n",
    "\n",
    "    key = list(latest_samples.keys())[0]\n",
    "    num_samples = latest_samples[key].shape[0]\n",
    "    for field_name, data in latest_samples.items():\n",
    "        assert data.shape[0] == num_samples, data.shape\n",
    "    \n",
    "    return latest_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b51b4ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sample = load_sequence(POSITIVE_PATH)\n",
    "n_sample = load_sequence(NEGATIVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea128ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_size = p_sample['observations'].shape[0]\n",
    "n_size = n_sample['observations'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8850f9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(x_sample, x_size):\n",
    "    input_x = []\n",
    "    seq = []\n",
    "    for i in range(0, x_size):\n",
    "        seq.append(x_sample['observations'][i])\n",
    "        if(x_sample['terminals'][i]):\n",
    "            seq = np.array(seq)\n",
    "            select_frame = np.linspace(0, seq.shape[0]-1, MAX_SEQ_LENGTH,endpoint=True,retstep=True,dtype=int)[0]\n",
    "            input_x.append(seq[select_frame])\n",
    "            seq = []\n",
    "    return np.array(input_x)\n",
    "\n",
    "def merge_input(p_input, n_input):\n",
    "    input_batch = []\n",
    "    label = []\n",
    "    for i in range(p_input.shape[0]):\n",
    "        input_batch.append(p_input[i])\n",
    "        label.append(1)\n",
    "    for i in range(n_input.shape[0]):\n",
    "        input_batch.append(n_input[i])\n",
    "        label.append(0)\n",
    "    \n",
    "    input_batch = np.array(input_batch).astype('float32')\n",
    "    label = np.array(label)\n",
    "    return input_batch, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14e3391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_input = prepare_input(p_sample, p_size)\n",
    "n_input = prepare_input(n_sample, n_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65e31cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = merge_input(p_input, n_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6559b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl_with_videos.models.feedforward import feedforward_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb5bfcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: feedforward_model\n",
      "inputs: [<tf.Tensor 'input_1:0' shape=(?, 6) dtype=float32>]\n",
      "WARNING:tensorflow:From C:\\Users\\irohc\\anaconda3\\envs\\drl_proj\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 42        \n",
      "=================================================================\n",
      "Total params: 84\n",
      "Trainable params: 84\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = feedforward_model([(6,)], 6, [6], output_activation = 'relu')\n",
    "feature_extractor.trainable = True\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44d2454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(keras.layers.Layer):\n",
    "    def __init__(self, sequence_length, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.position_embeddings = keras.layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # The inputs are of shape: `(batch_size, frames, num_features)`\n",
    "        length = tf.shape(inputs)[1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return inputs + embedded_positions\n",
    "\n",
    "#     def compute_mask(self, inputs, mask=None):\n",
    "#         mask = tf.reduce_any(tf.cast(inputs, \"bool\"), axis=-1)\n",
    "#         return mask\n",
    "\n",
    "class MultiHeadAttention(keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self,multiheads, head_dim,mask_right=False,**kwargs):\n",
    "        self.multiheads = multiheads\n",
    "        self.head_dim = head_dim\n",
    "        self.output_dim = multiheads * head_dim\n",
    "        self.mask_right = mask_right\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0][0],input_shape[0][1],self.output_dim) #shape=[batch_size,Q_sequence_length,self.multiheads*self.head_dim]\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.WQ = self.add_weight(name='WQ', \n",
    "                                  shape=(input_shape[0][-1].value, self.output_dim),#input_shape[0] -> Q_seq\n",
    "                                  initializer='glorot_uniform',\n",
    "                                  trainable=True)\n",
    "        self.WK = self.add_weight(name='WK', \n",
    "                                  shape=(input_shape[1][-1].value, self.output_dim),#input_shape[1] -> K_seq\n",
    "                                  initializer='glorot_uniform',\n",
    "                                  trainable=True)\n",
    "        self.WV = self.add_weight(name='WV', \n",
    "                                  shape=(input_shape[2][-1].value, self.output_dim),#input_shape[2] -> V_seq\n",
    "                                  initializer='glorot_uniform',\n",
    "                                  trainable=True)\n",
    "        super(MultiHeadAttention, self).build(input_shape)\n",
    "    \n",
    "    def Mask(self,inputs,seq_len,mode='add'):\n",
    "        if seq_len == None:\n",
    "            return inputs\n",
    "        else:\n",
    "            mask = K.one_hot(indices=seq_len[:,0],num_classes=K.shape(inputs)[1])#mask.shape=[batch_size,short_sequence_length],mask=[[0,0,0,0,1,0,0,..],[0,1,0,0,0,0,0...]...]\n",
    "            mask = 1 - K.cumsum(mask,axis=1)#mask.shape=[batch_size,short_sequence_length],mask=[[1,1,1,1,0,0,0,...],[1,0,0,0,0,0,0,...]...]\n",
    "            for _ in range(len(inputs.shape)-2):\n",
    "                mask = K.expand_dims(mask, 2)\n",
    "            if mode == 'mul':\n",
    "                return inputs * mask\n",
    "            elif mode == 'add':\n",
    "                return inputs - (1 - mask) * 1e12\n",
    "    \n",
    "    def call(self,QKVs):\n",
    "\n",
    "        if len(QKVs) == 3:\n",
    "            Q_seq,K_seq,V_seq = QKVs\n",
    "            Q_len,V_len = None,None\n",
    "        elif len(QKVs) == 5:\n",
    "            Q_seq,K_seq,V_seq,Q_len,V_len = QKVs\n",
    " \n",
    "        Q_seq = K.dot(Q_seq,self.WQ)#Q_seq.shape=[batch_size,Q_sequence_length,self.output_dim]=[batch_size,Q_sequence_length,self.multiheads*self.head_dim] \n",
    "        Q_seq = K.reshape(Q_seq,shape=(-1,K.shape(Q_seq)[1],self.multiheads,self.head_dim))#Q_seq.shape=[batch_size,Q_sequence_length,self.multiheads,self.head_dim]\n",
    "        Q_seq = K.permute_dimensions(Q_seq,pattern=(0,2,1,3))#Q_seq.shape=[batch_size,self.multiheads,Q_sequence_length,self.head_dim]\n",
    "\n",
    "        K_seq = K.dot(K_seq,self.WK)\n",
    "        K_seq = K.reshape(K_seq,shape=(-1,K.shape(K_seq)[1],self.multiheads,self.head_dim))\n",
    "        K_seq = K.permute_dimensions(K_seq,pattern=(0,2,1,3))\n",
    "\n",
    "        V_seq = K.dot(V_seq,self.WV)\n",
    "        V_seq = K.reshape(V_seq,shape=(-1,K.shape(V_seq)[1],self.multiheads,self.head_dim))\n",
    "        V_seq = K.permute_dimensions(V_seq,pattern=(0,2,1,3))\n",
    "\n",
    "        A = K.batch_dot(Q_seq,K_seq,axes=[3,3])/K.sqrt(K.cast(self.head_dim,dtype='float32'))#A.shape=[batch_size,self.multiheads,Q_sequence_length,K_sequence_length]\n",
    "        A = K.permute_dimensions(A,pattern=(0,3,2,1))#A.shape=[batch_size,K_sequence_length,Q_sequence_length,self.multiheads]\n",
    "\n",
    "        A = self.Mask(A,V_len,'add')\n",
    "        A = K.permute_dimensions(A,pattern=(0,3,2,1))#A.shape=[batch_size,self.multiheads,Q_sequence_length,K_sequence_length]\n",
    "        \n",
    "        if self.mask_right:\n",
    "            ones = K.ones_like(A[:1,:1])\n",
    "            lower_triangular = K.tf.matrix_band_part(ones,num_lower=-1,num_upper=0) \n",
    "            mask = (ones - lower_triangular) * 1e12 \n",
    "            A = A - mask #Element-wise subtractï¼ŒA.shape=[batch_size,self.multiheads,Q_sequence_length,K_sequence_length]\n",
    "        A = K.softmax(A) #A.shape=[batch_size,self.multiheads,Q_sequence_length,K_sequence_length]\n",
    "        #V_seq.shape=[batch_size,V_sequence_length,V_embedding_dim]\n",
    "        O_seq = K.batch_dot(A,V_seq,axes=[3,2])#O_seq.shape=[batch_size,self.multiheads,Q_sequence_length,V_sequence_length]\n",
    "        O_seq = K.permute_dimensions(O_seq,pattern=(0,2,1,3))#O_seq.shape=[batch_size,Q_sequence_length,self.multiheads,V_sequence_length]\n",
    "        O_seq = K.reshape(O_seq,shape=(-1,K.shape(O_seq)[1],self.output_dim))#O_seq.shape=[,Q_sequence_length,self.multiheads*self.head_dim]\n",
    "        O_seq = self.Mask(O_seq,Q_len,'mul')\n",
    "        return O_seq\n",
    "\n",
    "class TransformerEncoder(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = MultiHeadAttention(\n",
    "            num_heads, embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [keras.layers.Dense(dense_dim, activation='relu'), keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "#         self.layernorm_1 = keras.layers.LayerNormalization()\n",
    "#         self.layernorm_2 = keras.layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "\n",
    "        attention_output = self.attention([inputs, inputs, inputs])\n",
    "        proj_input = keras.layers.BatchNormalization()(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return keras.layers.BatchNormalization()(proj_input + proj_output)\n",
    "\n",
    "def Transformer(\n",
    "        input_shapes,\n",
    "        output_size,\n",
    "        feature_extractor,\n",
    "        *args,\n",
    "        **kwargs):\n",
    "    sequence_length = MAX_SEQ_LENGTH\n",
    "    embed_dim = 32\n",
    "    dense_dim = 16\n",
    "    num_heads = 1\n",
    "    video = keras.layers.Input(shape=input_shapes,name='video_input')\n",
    "    encoded_frame = keras.layers.TimeDistributed(keras.layers.Lambda(lambda x: feature_extractor(x)))(video)\n",
    "    \n",
    "    x = PositionalEmbedding(\n",
    "        sequence_length, embed_dim, name=\"frame_position_embedding\"\n",
    "    )(encoded_frame)\n",
    "    x = TransformerEncoder(embed_dim, dense_dim, num_heads, name=\"transformer_layer\")(x)\n",
    "    x = keras.layers.GlobalMaxPooling1D()(x)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "        \n",
    "    # encoded_vid = keras.layers.Dense(8, activation='relu')(encoded_vid)\n",
    "    outputs = keras.layers.Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[video],outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb331e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LRCNs(\n",
    "        input_shapes,\n",
    "        output_size,\n",
    "        feature_extractor,\n",
    "        hidden_state_num = 2,\n",
    "        hidden_state_size = (16, 8),\n",
    "        *args,\n",
    "        **kwargs):\n",
    "    feature_extractor.trainable = True\n",
    "    video = keras.layers.Input(shape=input_shapes,name='video_input')\n",
    "    encoded_frame = keras.layers.TimeDistributed(keras.layers.Lambda(lambda x: feature_extractor(x)))(video)\n",
    "    \n",
    "    for i in range(0, hidden_state_num - 1):\n",
    "        encoded_frame = keras.layers.LSTM(hidden_state_size[i], return_sequences=True)(encoded_frame)\n",
    "        \n",
    "    encoded_vid = keras.layers.LSTM(hidden_state_size[hidden_state_num-1], return_sequences=False)(encoded_frame)\n",
    "    encoded_vid = keras.layers.Dropout(0.3)(encoded_vid)\n",
    "        \n",
    "    # encoded_vid = keras.layers.Dense(8, activation='relu')(encoded_vid)\n",
    "    outputs = keras.layers.Dense(output_size, activation='softmax')(encoded_vid)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[video],outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df68711f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\irohc\\anaconda3\\envs\\drl_proj\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = LRCNs((None, 6), 2, feature_extractor)\n",
    "# model = Transformer((None, 6), 2, feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ac7c3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "video_input (InputLayer)     (None, None, 6)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 6)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 16)          1472      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 2,290\n",
      "Trainable params: 2,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8ca094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6341269e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1093 samples, validate on 194 samples\n",
      "Epoch 1/100\n",
      "1093/1093 [==============================] - 3s 3ms/sample - loss: 0.6808 - acc: 0.5590 - val_loss: 1.0032 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.6056 - acc: 0.7072 - val_loss: 1.2838 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.5908 - acc: 0.7072 - val_loss: 1.2017 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.5656 - acc: 0.7072 - val_loss: 1.3482 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.4707 - acc: 0.7548 - val_loss: 2.0661 - val_acc: 0.0206\n",
      "Epoch 6/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.3270 - acc: 0.8957 - val_loss: 2.5361 - val_acc: 0.0928\n",
      "Epoch 7/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.2442 - acc: 0.9442 - val_loss: 2.5318 - val_acc: 0.1598\n",
      "Epoch 8/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.2014 - acc: 0.9561 - val_loss: 1.8446 - val_acc: 0.4227\n",
      "Epoch 9/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.2114 - acc: 0.9478 - val_loss: 2.1576 - val_acc: 0.2938\n",
      "Epoch 10/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.1670 - acc: 0.9625 - val_loss: 2.2638 - val_acc: 0.2990\n",
      "Epoch 11/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.1691 - acc: 0.9625 - val_loss: 1.9548 - val_acc: 0.4278\n",
      "Epoch 12/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.1455 - acc: 0.9652 - val_loss: 3.2837 - val_acc: 0.1186\n",
      "Epoch 13/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.1561 - acc: 0.9652 - val_loss: 2.1272 - val_acc: 0.3918\n",
      "Epoch 14/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.1351 - acc: 0.9726 - val_loss: 2.7330 - val_acc: 0.2320\n",
      "Epoch 15/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.1320 - acc: 0.9689 - val_loss: 1.9621 - val_acc: 0.4330\n",
      "Epoch 16/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.1263 - acc: 0.9726 - val_loss: 2.7313 - val_acc: 0.2474\n",
      "Epoch 17/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.1272 - acc: 0.9707 - val_loss: 2.1672 - val_acc: 0.4124\n",
      "Epoch 18/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.1282 - acc: 0.9698 - val_loss: 1.4890 - val_acc: 0.5825\n",
      "Epoch 19/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.1418 - acc: 0.9625 - val_loss: 2.6973 - val_acc: 0.2474\n",
      "Epoch 20/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.1189 - acc: 0.9771 - val_loss: 2.2977 - val_acc: 0.3402\n",
      "Epoch 21/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.1201 - acc: 0.9716 - val_loss: 2.5933 - val_acc: 0.2732\n",
      "Epoch 22/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.1168 - acc: 0.9762 - val_loss: 2.4947 - val_acc: 0.2784\n",
      "Epoch 23/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.1094 - acc: 0.9716 - val_loss: 1.9279 - val_acc: 0.4381\n",
      "Epoch 24/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.1056 - acc: 0.9753 - val_loss: 1.7494 - val_acc: 0.4278\n",
      "Epoch 25/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0993 - acc: 0.9753 - val_loss: 1.8231 - val_acc: 0.4691\n",
      "Epoch 26/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.1030 - acc: 0.9771 - val_loss: 1.7370 - val_acc: 0.5103\n",
      "Epoch 27/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0847 - acc: 0.9835 - val_loss: 1.8243 - val_acc: 0.4639\n",
      "Epoch 28/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0850 - acc: 0.9808 - val_loss: 1.1819 - val_acc: 0.5876\n",
      "Epoch 29/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0568 - acc: 0.9863 - val_loss: 1.7792 - val_acc: 0.5412\n",
      "Epoch 30/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0774 - acc: 0.9835 - val_loss: 2.8135 - val_acc: 0.2680\n",
      "Epoch 31/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0786 - acc: 0.9808 - val_loss: 1.2288 - val_acc: 0.6753\n",
      "Epoch 32/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0618 - acc: 0.9863 - val_loss: 0.5629 - val_acc: 0.7629\n",
      "Epoch 33/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0597 - acc: 0.9863 - val_loss: 1.5750 - val_acc: 0.5103\n",
      "Epoch 34/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0682 - acc: 0.9808 - val_loss: 0.8015 - val_acc: 0.7577\n",
      "Epoch 35/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0930 - acc: 0.9817 - val_loss: 0.8955 - val_acc: 0.7526\n",
      "Epoch 36/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0568 - acc: 0.9863 - val_loss: 1.7386 - val_acc: 0.5206\n",
      "Epoch 37/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0542 - acc: 0.9890 - val_loss: 1.0096 - val_acc: 0.6598\n",
      "Epoch 38/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0471 - acc: 0.9899 - val_loss: 1.1093 - val_acc: 0.5567\n",
      "Epoch 39/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0569 - acc: 0.9881 - val_loss: 0.9347 - val_acc: 0.6753\n",
      "Epoch 40/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0506 - acc: 0.9863 - val_loss: 0.6180 - val_acc: 0.7732\n",
      "Epoch 41/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0448 - acc: 0.9890 - val_loss: 0.7598 - val_acc: 0.7680\n",
      "Epoch 42/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0379 - acc: 0.9918 - val_loss: 0.5983 - val_acc: 0.7629\n",
      "Epoch 43/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0304 - acc: 0.9918 - val_loss: 1.3625 - val_acc: 0.5825\n",
      "Epoch 44/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0342 - acc: 0.9918 - val_loss: 0.6881 - val_acc: 0.7938\n",
      "Epoch 45/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0292 - acc: 0.9945 - val_loss: 0.6483 - val_acc: 0.8196\n",
      "Epoch 46/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0599 - acc: 0.9817 - val_loss: 1.9595 - val_acc: 0.4330\n",
      "Epoch 47/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0373 - acc: 0.9872 - val_loss: 1.0336 - val_acc: 0.5670\n",
      "Epoch 48/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0447 - acc: 0.9872 - val_loss: 2.0608 - val_acc: 0.3454\n",
      "Epoch 49/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0240 - acc: 0.9945 - val_loss: 0.6770 - val_acc: 0.7474\n",
      "Epoch 50/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0192 - acc: 0.9954 - val_loss: 0.1857 - val_acc: 0.9227\n",
      "Epoch 51/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0284 - acc: 0.9927 - val_loss: 0.4018 - val_acc: 0.8299\n",
      "Epoch 52/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0221 - acc: 0.9936 - val_loss: 1.8205 - val_acc: 0.4175\n",
      "Epoch 53/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0367 - acc: 0.9918 - val_loss: 0.9172 - val_acc: 0.7010\n",
      "Epoch 54/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0282 - acc: 0.9909 - val_loss: 0.6672 - val_acc: 0.7577\n",
      "Epoch 55/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0235 - acc: 0.9927 - val_loss: 0.6121 - val_acc: 0.7990\n",
      "Epoch 56/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0218 - acc: 0.9918 - val_loss: 0.2891 - val_acc: 0.9124\n",
      "Epoch 57/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0218 - acc: 0.9927 - val_loss: 0.6520 - val_acc: 0.8196\n",
      "Epoch 58/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0248 - acc: 0.9909 - val_loss: 0.9166 - val_acc: 0.7423\n",
      "Epoch 59/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0173 - acc: 0.9936 - val_loss: 0.4447 - val_acc: 0.8866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0207 - acc: 0.9918 - val_loss: 0.9731 - val_acc: 0.7526\n",
      "Epoch 61/100\n",
      "1093/1093 [==============================] - 2s 2ms/sample - loss: 0.0133 - acc: 0.9954 - val_loss: 0.5152 - val_acc: 0.8814\n",
      "Epoch 62/100\n",
      " 900/1093 [=======================>......] - ETA: 0s - loss: 0.0437 - acc: 0.9922"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4740/1232959489.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model.fit(train_x, train_y, shuffle=True,\n\u001b[0;32m      2\u001b[0m       \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m       verbose=1)\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\drl_proj\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drl_proj\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drl_proj\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3076\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\drl_proj\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y, shuffle=True,\n",
    "      batch_size=50, epochs=100, validation_split=0.15,\n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd92a85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3b0466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847d9832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drl_proj",
   "language": "python",
   "name": "drl_proj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
